{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dceb504-0b94-4208-ae67-05add44c6dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "L'objectif de ce projet est d'observer s'il existe des 'déserts sportifs', \n",
    "lieux en France où les infrastrcutures sportives manquent. \n",
    "La question sera alors d'essayer d'expliquer ces déserts sportifs, que ce soit par des raisons économiques ou politiques. \n",
    "Enfin, il s'agira de comparer la carte des déserts sportifs avec d'autres cartes connues, à l'instar des déserts médicaux.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db6bb8ed-95e7-4bc6-abae-8c01bcc63f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Il convient d'abord d'importer tous les modules python nécessaires au travail\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import numpy.linalg as al\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from cartiflette import carti_download\n",
    "import requests\n",
    "import zipfile\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fa75cf83-0d12-46ca-aac0-28c94bccc294",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "On importe ensuite nos jeux de données\n",
    "Le jeu de données principal\n",
    "'''\n",
    "url = \"https://data.sports.gouv.fr/api/explore/v2.1/catalog/datasets/equipements-sportifs/exports/csv?lang=fr&timezone=Europe%2FBerlin&use_labels=true&delimiter=%3B\"\n",
    "equipement = pd.read_csv(url, sep=\";\", low_memory=False)\n",
    "\n",
    "'''\n",
    "Un jeu de données csv sur des informations économiques et démographiques au niveau des communes\n",
    "'''\n",
    "\n",
    "urlpop = \"https://www.insee.fr/fr/statistiques/fichier/2521169/base_cc_comparateur_csv.zip\"\n",
    "response = requests.get(urlpop)\n",
    "\n",
    "with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
    "    with z.open(\"base_cc_comparateur.csv\") as csvfile:\n",
    "        df_communes = pd.read_csv(csvfile, sep=\";\", low_memory=False)\n",
    "\n",
    "'''\n",
    "Jeu de données politiques au niveau des communes: résultats des législatives 2024 (2nd tour)\n",
    "'''\n",
    "\n",
    "url2=\"https://www.data.gouv.fr/api/1/datasets/r/5a8088fd-8168-402a-9f40-c48daab88cd1\"\n",
    "legislatives2=pd.read_csv(url2, sep=\";\", low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "285ed2c8-c20b-40e3-b2ff-8b4b4a09c9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Il s'agit maintenant de laver nos jeux de données afin de les réunir ensuite à l'aide des codes INSEE.\n",
    "On conserve seulement les variables qui peuvent nous intéresser.\n",
    "'''\n",
    "\n",
    "cols = [\"Nom de l'installation sportive\", \"Code Postal\", \"Commune nom\", \"Commune INSEE\", \"Département Code\", \"Département Nom\", \"Densite Catégorie\", \"Nom de l'équipement sportif\", \"Type d'équipement sportif\", \"Longitude\", \"Latitude\"]\n",
    "equipement = equipement[cols]\n",
    "\n",
    "cols=[\"CODGEO\", \"P22_POP\", \"NAISD24\", \"DECESD24\", \"P22_MEN\",\"MED21\", \"TP6021\", \"P22_CHOM1564\"]\n",
    "df_communes = df_communes[cols]\n",
    "\n",
    "cols=[\"Code commune\", \"Libellé commune\"]\n",
    "cols= cols + [(f\"% Voix/exprimés {i}\") for i in range(1,4)]+[ (f\"Nuance candidat {i}\") for i in range(1, 4)]\n",
    "legislatives2= legislatives2[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "733e5061-647e-4a29-acd5-05ca7b2ffcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "On renomme maintenant les colonnes afin de pouvoir concatener les dataframes. \n",
    "'''\n",
    "\n",
    "df_communes = df_communes.rename(columns={\"CODGEO\": \"Commune INSEE\"})\n",
    "legislatives2 = legislatives2.rename(columns={\"Code commune\": \"Commune INSEE\"})\n",
    "\n",
    "df_final = (\n",
    "    equipement\n",
    "    .merge(df_communes, on=\"Commune INSEE\", how=\"left\")\n",
    "    .merge(legislatives2, on=\"Commune INSEE\", how=\"left\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "42c0a575-e110-46de-9e47-192dbd81e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "On ajoute dans ce dataframe uniquement le parti politique en tête lors des élections de 2024, c'est-à-dire la nuance qui a eu\n",
    "le plus de % Voix/exprimés. Pour calculer le max il faut donc remplacer les valeurs prises qui ne sont pour l'instant pas dans le bon format.\n",
    "'''\n",
    "cols_voix = [\"% Voix/exprimés 1\", \"% Voix/exprimés 2\", \"% Voix/exprimés 3\"]\n",
    "\n",
    "for c in cols_voix:\n",
    "    df_final[c] = (df_final[c].astype(str).str.replace(\"%\", \"\", regex=False).str.replace(\",\", \".\", regex=False).str.strip())\n",
    "\n",
    "df_final[\"% Voix/exprimés 3\"]=df_final[\"% Voix/exprimés 3\"].str.replace(\"nan\",\"0\")\n",
    "\n",
    "cols_valeurs = df_final.columns[19:22]\n",
    "cols_associees = df_final.columns[22:25]\n",
    "\n",
    "valeurs = df_final[cols_valeurs].to_numpy()\n",
    "associees = df_final[cols_associees].to_numpy()\n",
    "idx_max = np.argmax(valeurs, axis=1)\n",
    "df_final[\"Score vainqueur\"] = valeurs[np.arange(len(df_final)), idx_max]\n",
    "df_final[\"Parti vainqueur\"] = associees[np.arange(len(df_final)), idx_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6660e8e6-1a55-498e-9c5e-b7b993f9e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "En faisant le test avec ma commune d'origine, on se rend compte que des lignes sont parfois en double, voire triple, on va donc supprimer ces doublons.\n",
    "'''\n",
    "\n",
    "test=df_final[df_final[\"Commune nom\"] == \"Eschau\"]\n",
    "\n",
    "df_final = df_final.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2555468b-159b-4787-bf2e-3b787b87f59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There was an error while reading the file from the URL: https://minio.lab.sspcloud.fr/projet-cartiflette/production/provider=IGN/dataset_family=ADMINEXPRESS/source=EXPRESS-COG-CARTO-TERRITOIRE/year=2022/administrative_level=DEPARTEMENT/crs=4326/FRANCE_ENTIERE_DROM_RAPPROCHES=France/vectorfile_format=GPKG/territory=metropole/simplification=50/raw.GPKG\n",
      "Error message: '/vsimem/pyogrio_b16dc7e26e0047288627a699859ea963' not recognized as being in a supported file format.; It might help to specify the correct driver explicitly by prefixing the file path with '<DRIVER>:', e.g. 'CSV:path'.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All objects passed were None",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[133]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     12\u001b[39m gdf_pts = gpd.GeoDataFrame(\n\u001b[32m     13\u001b[39m     df_final,\n\u001b[32m     14\u001b[39m     geometry=gpd.points_from_xy(df_final[\u001b[33m\"\u001b[39m\u001b[33mLongitude\u001b[39m\u001b[33m\"\u001b[39m], df_final[\u001b[33m\"\u001b[39m\u001b[33mLatitude\u001b[39m\u001b[33m\"\u001b[39m]),\n\u001b[32m     15\u001b[39m     crs=\u001b[33m\"\u001b[39m\u001b[33mEPSG:4326\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Coordonnées géographiques WGS84\u001b[39;00m\n\u001b[32m     16\u001b[39m )\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# --- 3️⃣ Télécharger un fond de carte (France entière)\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# ✅ Ici : format GPKG (GeoPackage), plus stable que TopoJSON\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m shp_communes = \u001b[43mcarti_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFrance\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                       \u001b[49m\u001b[38;5;66;43;03m# pas de 'values=' !\u001b[39;49;00m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4326\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mborders\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDEPARTEMENT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvectorfile_format\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpkg\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# ou \"geojson\" si tu préfères\u001b[39;49;00m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43msimplification\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilter_by\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFRANCE_ENTIERE_DROM_RAPPROCHES\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEXPRESS-COG-CARTO-TERRITOIRE\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43myear\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2022\u001b[39;49m\n\u001b[32m     29\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# --- 4️⃣ Charger le fond de carte dans GeoPandas\u001b[39;00m\n\u001b[32m     32\u001b[39m gdf_france = gpd.read_file(shp_communes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/cartiflette/client.py:257\u001b[39m, in \u001b[36mcarti_download\u001b[39m\u001b[34m(values, borders, filter_by, territory, vectorfile_format, year, crs, simplification, bucket, path_within_bucket, provider, dataset_family, source, filename, return_as_json, *args, **kwargs)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    216\u001b[39m \u001b[33;03mCalls CartifletteSession.get_dataset\u001b[39;00m\n\u001b[32m    217\u001b[39m \u001b[33;03mDownloads and aggregates official geographic datasets using the Cartiflette API\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    253\u001b[39m \u001b[33;03m        if return_as_json is True.\u001b[39;00m\n\u001b[32m    254\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m CartifletteSession() \u001b[38;5;28;01mas\u001b[39;00m carti_session:\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcarti_session\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mborders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mborders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilter_by\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilter_by\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m        \u001b[49m\u001b[43mterritory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mterritory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvectorfile_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvectorfile_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m        \u001b[49m\u001b[43myear\u001b[49m\u001b[43m=\u001b[49m\u001b[43myear\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m        \u001b[49m\u001b[43msimplification\u001b[49m\u001b[43m=\u001b[49m\u001b[43msimplification\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_within_bucket\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_within_bucket\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprovider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    270\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset_family\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_family\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_as_json\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_as_json\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/cartiflette/client.py:188\u001b[39m, in \u001b[36mCartifletteSession.get_dataset\u001b[39m\u001b[34m(self, values, borders, filter_by, territory, vectorfile_format, year, crs, simplification, bucket, path_within_bucket, provider, dataset_family, source, filename, return_as_json, *args, **kwargs)\u001b[39m\n\u001b[32m    185\u001b[39m     gdf_list.append(gdf_single)\n\u001b[32m    187\u001b[39m \u001b[38;5;66;03m# Concatenate the list of GeoDataFrames into a single GeoDataFrame\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m188\u001b[39m concatenated_gdf = \u001b[43mgpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgdf_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_as_json \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m concatenated_gdf.to_json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/core/reshape/concat.py:382\u001b[39m, in \u001b[36mconcat\u001b[39m\u001b[34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[39m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m using_copy_on_write():\n\u001b[32m    380\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m382\u001b[39m op = \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnames\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m op.get_result()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/core/reshape/concat.py:445\u001b[39m, in \u001b[36m_Concatenator.__init__\u001b[39m\u001b[34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[39m\n\u001b[32m    442\u001b[39m \u001b[38;5;28mself\u001b[39m.verify_integrity = verify_integrity\n\u001b[32m    443\u001b[39m \u001b[38;5;28mself\u001b[39m.copy = copy\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m objs, keys = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_clean_keys_and_objs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m \u001b[38;5;66;03m# figure out what our result ndim is going to be\u001b[39;00m\n\u001b[32m    448\u001b[39m ndims = \u001b[38;5;28mself\u001b[39m._get_ndims(objs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/python/lib/python3.13/site-packages/pandas/core/reshape/concat.py:541\u001b[39m, in \u001b[36m_Concatenator._clean_keys_and_objs\u001b[39m\u001b[34m(self, objs, keys)\u001b[39m\n\u001b[32m    538\u001b[39m         keys = Index(clean_keys, name=name, dtype=\u001b[38;5;28mgetattr\u001b[39m(keys, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    540\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs_list) == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m541\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAll objects passed were None\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m objs_list, keys\n",
      "\u001b[31mValueError\u001b[39m: All objects passed were None"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Maintenant essayons de faire une carte de la france avec toutes les infrastructures sportives.\n",
    "'''\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from cartiflette import carti_download\n",
    "\n",
    "# --- 1️⃣ Nettoyer les données : garder uniquement les lignes avec coordonnées\n",
    "df_final = df_final.dropna(subset=[\"Longitude\", \"Latitude\"])\n",
    "\n",
    "# --- 2️⃣ Créer le GeoDataFrame des points\n",
    "gdf_pts = gpd.GeoDataFrame(\n",
    "    df_final,\n",
    "    geometry=gpd.points_from_xy(df_final[\"Longitude\"], df_final[\"Latitude\"]),\n",
    "    crs=\"EPSG:4326\"  # Coordonnées géographiques WGS84\n",
    ")\n",
    "\n",
    "# --- 3️⃣ Télécharger un fond de carte (France entière)\n",
    "# ✅ Ici : format GPKG (GeoPackage), plus stable que TopoJSON\n",
    "shp_communes = carti_download(\n",
    "    \"France\",                       # pas de 'values=' !\n",
    "    crs=4326,\n",
    "    borders=\"DEPARTEMENT\",\n",
    "    vectorfile_format=\"gpkg\",       # ou \"geojson\" si tu préfères\n",
    "    simplification=50,\n",
    "    filter_by=\"FRANCE_ENTIERE_DROM_RAPPROCHES\",\n",
    "    source=\"EXPRESS-COG-CARTO-TERRITOIRE\",\n",
    "    year=2022\n",
    ")\n",
    "\n",
    "# --- 4️⃣ Charger le fond de carte dans GeoPandas\n",
    "gdf_france = gpd.read_file(shp_communes)\n",
    "\n",
    "# --- 5️⃣ Harmoniser les projections (Lambert-93 pour la France)\n",
    "gdf_france = gdf_france.to_crs(\"EPSG:2154\")\n",
    "gdf_pts = gdf_pts.to_crs(\"EPSG:2154\")\n",
    "\n",
    "# --- 6️⃣ Afficher la carte\n",
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "\n",
    "# Tracer le fond (contours des départements)\n",
    "gdf_france.boundary.plot(ax=ax, linewidth=0.5, color=\"gray\")\n",
    "\n",
    "# Ajouter les points des infrastructures\n",
    "gdf_pts.plot(ax=ax, markersize=3, alpha=0.6, color=\"red\")\n",
    "\n",
    "# Mise en forme\n",
    "ax.set_title(\"Localisation des infrastructures sportives en France\", fontsize=14)\n",
    "ax.set_axis_off()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b4d41f-75a2-4c93-8725-88671bf8ed29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
